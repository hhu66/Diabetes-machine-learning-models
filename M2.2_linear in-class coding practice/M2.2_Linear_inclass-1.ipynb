{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eed391",
   "metadata": {},
   "source": [
    "## Linear methods for regression and classification\n",
    "In this jupyter notebook, we will practice the topics covered in the lectures. Specially, we will do hands-on practice of:\n",
    "- load and prepare data for machine learning model training and testing\n",
    "- train and test linear models (linear regression (lasso/ridge), polynomial regression, and logistic regression)\n",
    "- compare and understand model performance \n",
    "\n",
    "For implementations that have fixed results, we provide running examples for your reference. *You might get slightly different results due to the sklearn version you are using, just leave a comment to indicate your version where you get different results.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acb55f",
   "metadata": {},
   "source": [
    "## Linear Regression and Polynomial Regression\n",
    "In this section, we will explore the diabetes dataset:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes <br>\n",
    "\n",
    "This dataset contains n = 442 diabetes patients' information of ten variables: age, sex, body mass index, average blood pressure, and six blood serum measurements. Each patient has a quantitative value of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "We will fit different regression models to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target variable <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different regression models (linear/lasso/ridge) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients.\n",
    "\n",
    "**Note:** please always add comments to explain your observations/findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab86d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6354a20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31661c",
   "metadata": {},
   "source": [
    "Sklearn version: 1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6253bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fb790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different ways to load the dataset, please make sure you understand the mechanism\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "data = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355e95",
   "metadata": {},
   "source": [
    "### Basic dataset exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e585c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape, data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f34331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82cc4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature explanations\n",
    "#age in years\n",
    "#sex\n",
    "#bmi body mass index\n",
    "#bp average blood pressure\n",
    "#s1 tc, total serum cholesterol\n",
    "#s2 ldl, low-density lipoproteins\n",
    "#s3 hdl, high-density lipoproteins\n",
    "#s4 tch, total cholesterol / HDL\n",
    "#s5 ltg, possibly log of serum triglycerides level\n",
    "#s6 glu, blood sugar level\n",
    "\n",
    "#Target explanation\n",
    "#A quantitative measure of disease prpgression one year after baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abcc0287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe381e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>152.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>77.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>140.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.028</td>\n",
       "      <td>211.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.136</td>\n",
       "      <td>346.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      sex      bmi       bp       s1       s2       s3       s4  \\\n",
       "count  442.000  442.000  442.000  442.000  442.000  442.000  442.000  442.000   \n",
       "mean    -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   -0.000   \n",
       "std      0.048    0.048    0.048    0.048    0.048    0.048    0.048    0.048   \n",
       "min     -0.107   -0.045   -0.090   -0.112   -0.127   -0.116   -0.102   -0.076   \n",
       "25%     -0.037   -0.045   -0.034   -0.037   -0.034   -0.030   -0.035   -0.039   \n",
       "50%      0.005   -0.045   -0.007   -0.006   -0.004   -0.004   -0.007   -0.003   \n",
       "75%      0.038    0.051    0.031    0.036    0.028    0.030    0.029    0.034   \n",
       "max      0.111    0.051    0.171    0.132    0.154    0.199    0.181    0.185   \n",
       "\n",
       "            s5       s6   target  \n",
       "count  442.000  442.000  442.000  \n",
       "mean     0.000    0.000  152.133  \n",
       "std      0.048    0.048   77.093  \n",
       "min     -0.126   -0.138   25.000  \n",
       "25%     -0.033   -0.033   87.000  \n",
       "50%     -0.002   -0.001  140.500  \n",
       "75%      0.032    0.028  211.500  \n",
       "max      0.134    0.136  346.000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(data.frame.describe(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3e48c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAb60lEQVR4nO3de7xVdZ3/8ddbQLxgAnKGQZRARR3GR5Ieb2WmkuWlEepnauOvqAcNmVZW0xTaw7LHNDM4NTnN/FKjvJwaL6jpD9IpJbxlk+RBUcHLD0IQlctRI2+lqZ/fH+u7Zbs5+5x1jqy9z2a9n4/HeZx1X5+9OLz32t+91ncpIjAzs/LYptkFmJlZYzn4zcxKxsFvZlYyDn4zs5Jx8JuZlYyD38ysZBz8VmqSQtJeDdjPeZL+Kw2Pk/SCpEFbaNsXSzo3DR8p6Yktsd20vfdIenRLbc8GBge/1ZXCqfLzuqQ/Vo2f1qAatmiQDQQR8XhEDIuI13paTtInJN2VY3unR8Q/bonaat8II+JXEbHPlti2DRyDm12ADVwRMawyLGkV8KmI+GVftiFpcES8uqVrs4ykQb29gZjV8hm/9ZmkgyX9RtJGSWsl/R9J21bND0lnSloOLE/TvpKWfUrSp6rPLCUNlfQdSY9LWp+aLraXtCPwc2DXqk8au9bUcoikddXNJpI+JOmBPLXWbOt2SZ+qGn/TGbekfSUtkPSspEclndzDMZog6Q5Jz0taAIyqmjc+vf7BVftZmZZ9TNJpkv4KuBg4LL3ujWnZyyVdJOm/Jb0IHJWmfatm/+dIelrSqupPZz29Rkl3psn3p32eUvuJS9JfpW1slLRM0olV8y6X9H1JN6XXskjSnvWOkTWPg9/64zXgi2RhdhgwBTijZplpwCHAJEnHAl8C3gfsBRxZs+xsYG9gcpo/Fvh6RLwIHAc8lZpGhkXEU9UrRsQi4EXg6KrJfwtc2Ydae5XehBak7f4FcCpwoaRJdVa5Elic9vuPwPQetvsfwHERsRPwLmBJRDwMnA78Jr3u4TWv75+AnYDumoL+Mu13bNrvHEm9NtdExBFpcP+0z7k1tQ4BfgbcQnYMPgdcUbPtU4FvAiOAFalOG2Ac/NZnEbE4Iu6OiFcjYhXwA+C9NYv9S0Q8GxF/BE4GLouIZRHxEnBeZSFJAmYCX0zLPw/8M1mA5HUV8NG0vZ2A49O0vLXm8UFgVURclrZ1H/BT4CO1C0oaBxwEnBsRL0fEnWSBWc/rwH6Sto+ItRGxrJda5kXEryPi9Yj4U51lKvu+A7iJ7N/grToUGAbMjohXIuJW4EbSsU9uiIjfpua9K8jezG2AcfBbn0naW9KNqYnlObKgHlWz2Jqq4V1rxquH24AdgMWp+WAj8Is0Pa8rgQ9LGgp8GLg3Ilb3odY83g4cUqkx1Xka2dl1rV2B36dPLBWru9toWuYUsrP7tamZZN9ealnTy/zu9r1rvYX7YFdgTUS8XrPtsVXj66qGXyJ7o7ABxsFv/XER8AgwMSLeBpwDqGaZ6m5f1wK7VY3vXjX8NPBH4K8jYnj62bnqi+Veu4+NiIfIAug43tzMk7fWihfJ3oQqqkN9DXBHVY3DU3PIZ7rZzlpgRGrGqRjXQ/03R8QxwJhU6w8rs+qtUm9bSXf7rjSR9fQae/MUsLuk6twYBzzZh23YAODgt/7YCXgOeCGdnXYXftWuAT6ZvhjcATi3MiOdPf4QuEDSXwBIGivpA2mR9cAuknbuZR9XAmcBRwDX9rPWJWSfHHZIXzzPqJp3I7C3pI9JGpJ+Dkpfwr5J+rTRCXxT0raSDgf+prsdShotaWoK6peBF8iafiqvfbd6X0b3orLv95A1U1WOSU+vsbLPPepscxHZWfxX0us/Mr2uq/tRnzWRg9/648tkZ9bPk4X23J4Wjoifk32BeRvZF353p1kvp99frUxPzTG/BPZJ6z5C1l6/MjWx1GuyuIqs7f7WiHi6n7VeALxCFn4dZG3UldfwPPB+su8eniJr0jgfGFpnW39L9uX2s8A3gB/XWW4bsi++n0rLvpdNb063AsuAdZKe7n71bq0Dfp+2eQVwejqOPb7G5DygIx3rN30vEBGvkAX9cWSf1C4EPl61bWsR8oNYrNHSWfJSYKiv8TdrPJ/xW0Mou7Z+qKQRZGfKP3PomzWHg98a5dPABuB3ZNfW9/a9gJkVxE09ZmYl4zN+M7OSaYlO2kaNGhXjx49vdhlmZi1l8eLFT0fEZjdDtkTwjx8/ns7OzmaXYWbWUiR1e8e4m3rMzErGwW9mVjIOfjOzknHwm5mVjIPfzKxkHPxmZiVTaPBL+mJ6LudSSVdJ2k7Zs0gXSVohaW4/u5w1M7N+Kiz4JY0FPg+0R8R+wCCyLm3PBy6IiL3Iuo6t7Q/czMwKVHRTz2Bge0mDyZ76s5bsodjXpfkdZA/lNjOzBinszt2IeFLSd4DHyR6tdwuwGNhY1R3vE7z5eZ1vkDST7CHcjBtX96l1A9r4WTc1bF+rZp/QsH2ZWWsrsqlnBDAVmED2kOYdgWPzrh8RcyKiPSLa29r68txtMzPrSZFNPe8DHouIroj4M3A98G5geGr6gewB3H5Qs5lZAxUZ/I8Dh6aHOguYAjxE9tzVk9Iy04F5BdZgZmY1Cgv+iFhE9iXuvcCDaV9zyB6s/SVJK4BdgEuKqsHMzDZXaLfMEfEN4Bs1k1cCBxe5XzMzq8937pqZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzkinyYev7SFpS9fOcpC9IGilpgaTl6feIomowM7PNFfnoxUcjYnJETAYOBF4CbgBmAQsjYiKwMI2bmVmDNKqpZwrwu4hYDUwFOtL0DmBag2owMzMaF/ynAlel4dERsTYNrwNGN6gGMzOjAcEvaVvgRODa2nkREUDUWW+mpE5JnV1dXQVXaWZWHo044z8OuDci1qfx9ZLGAKTfG7pbKSLmRER7RLS3tbU1oEwzs3JoRPB/lE3NPADzgelpeDowrwE1mJlZUmjwS9oROAa4vmrybOAYScuB96VxMzNrkMFFbjwiXgR2qZn2DNlVPmZm1gSFBr81z/hZNzVsX6tmn9CwfZnZW+cuG8zMSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzknHwm5mVjIPfzKxkHPxmZiXjbplti2pkd9DgLqHN+sNn/GZmJVP0oxeHS7pO0iOSHpZ0mKSRkhZIWp5+jyiyBjMze7Oiz/i/B/wiIvYF9gceBmYBCyNiIrAwjZuZWYMUFvySdgaOAC4BiIhXImIjMBXoSIt1ANOKqsHMzDZX5Bn/BKALuEzSfZJ+JGlHYHRErE3LrANGd7eypJmSOiV1dnV1FVimmVm5FBn8g4EDgIsi4p3Ai9Q060REANHdyhExJyLaI6K9ra2twDLNzMqlyOB/AngiIhal8evI3gjWSxoDkH5vKLAGMzOrUVjwR8Q6YI2kfdKkKcBDwHxgepo2HZhXVA1mZra5om/g+hxwhaRtgZXAJ8nebK6RNANYDZxccA1mZlal0OCPiCVAezezphS5XzMzq8937pqZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzknHwm5mVTKFP4JK0CngeeA14NSLaJY0E5gLjgVXAyRHx+yLrMDOzTRpxxn9UREyOiMojGGcBCyNiIrAwjZuZWYPkCn5JO0raJg3vLelESUP6uc+pQEca7gCm9XM7ZmbWD3mbeu4E3iNpBHALcA9wCnBaL+sFcIukAH4QEXOA0RGxNs1fB4zubkVJM4GZAOPGjctZppXZ+Fk3NXR/q2af0ND9mW0peZt6FBEvAR8GLoyIjwB/nWO9wyPiAOA44ExJR1TPjIgge3PYTETMiYj2iGhva2vLWaaZmfUmd/BLOozsDL9yWjWot5Ui4sn0ewNwA3AwsF7SmLTRMcCGvhZtZmb9lzf4vwCcDdwQEcsk7QHc1tMK6XuBnSrDwPuBpcB8YHpabDowrx91m5lZP+Vq44+IO4A7JO2QxlcCn+9ltdHADZIq+7kyIn4h6R7gGkkzgNXAyf0t3szM+i5X8KdmnkuAYcA4SfsDn46IM+qtk94c9u9m+jPAlP6Va2Zmb1Xepp5/Bz4APAMQEfcDR/S0gpmZDUy5b+CKiDU1k17bwrWYmVkD5L2Of42kdwGRbtw6C3i4uLLMzKwoec/4TwfOBMYCTwKT07iZmbWYvFf1PE3vd+mamVkL6DH4Jf0nde6sBYiI3i7pNDOzAaa3M/7OhlRhZmYN02PwR0RH9bikt2WT4/lCqzIzs8Lk7Za5XdKDwAPAUkn3Szqw2NLMzKwIeS/nvBQ4IyJ+BSDpcOAy4B1FFWZmZsXIeznna5XQB4iIu4BXiynJzMyKlPeM/w5JPwCuIrvK5xTgdkkHAETEvQXVZ2ZmW1je4K90tvaNmunvJHsjOHqLVWRmZoXKewPXUUUXYmZmjZG3W+bhwMeB8dXr+AYuM7PWk7ep57+Bu4EHgdeLK8fMWoUfbt+68gb/dhHxpUIrMTOzhsh7OedPJP2dpDGSRlZ+8qwoaZCk+yTdmMYnSFokaYWkuZK27Xf1ZmbWZ3nP+F8Bvg18jU2dtgWwR451K333vy2Nnw9cEBFXS7oYmAFclLtiswGokc0ebvKwtyrvGf/fA3tFxPiImJB+eg19SbsBJwA/SuMiu/TzurRIBzCtz1WbmVm/5Q3+FcBL/dj+vwNfYdMXwrsAGyOictfvE2QPd9mMpJmSOiV1dnV19WPXZmbWnbxNPS8CSyTdBrxcmdjT5ZySPghsiIjFko7sa2ERMQeYA9De3l73mQBmZtY3eYP//6afvng3cKKk44HtyNr4vwcMlzQ4nfXvRvYoRzMza5C8d+529L7UZuucDZwNkM74vxwRp0m6FjgJuBqYDszr67bNzKz/8vbHP1HSdZIekrSy8tPPfX4V+JKkFWRt/pf0cztmZtYPeZt6LiProO0C4Cjgk+T/YpiIuB24PQ2vBA7uS5Fvhe8utK2dLyW1vsob3ttHxEJAEbE6Is4ju0zTzMxaTN4z/pclbQMsl/RZsi9khxVXlpmZFSXvGf9ZwA7A54EDgY+RfTFrZmYtJu9VPfekwRckzQCGRcRzxZVlZmZFyXtVz5WS3iZpR2Ap8JCkfyi2NDMzK0Lepp5J6Qx/GvBzYAJZc4+ZmbWYvME/RNIQsuCfHxF/ZlMvnWZm1kLyBv/FwCpgR+BOSW8H3MZvZtaC8l7OuXNEjAWQNBR4nOxGLjMzazE9nvFL+qqkw8j61qn4TWRerbeemZkNXL2d8T8CfATYQ9Kv0vgukvaJiEcLr87MzLa43tr4NwLnkD2I5UiybpUBZkn6n+LKMjOzovR2xv8B4OvAnsB3gQeAFyPik0UXZmZmxejxjD8izomIKWRX9PwEGAS0SbpL0s8aUJ+ZmW1hea/quTkiOoFOSZ+JiMMljSqyMDMzK0au6/gj4itVo59I054uoiAzMytW7oepVETE/UUUYmZmjdHn4M9L0naSfivpfknLJH0zTZ8gaZGkFZLmStq2qBrMzGxzhQU/8DJwdETsD0wGjpV0KHA+cEFE7AX8HphRYA1mZlajsOBPd/e+kEaHpJ8AjgauS9M7yDp+MzOzBinyjB9JgyQtATYAC4DfARurunt4AhhbZ92ZkjoldXZ1dRVZpplZqRQa/BHxWkRMBnYDDgb27cO6cyKiPSLa29raiirRzKx0Cg3+iojYCNwGHAYMl1S5f2A3sge3m5lZgxR5VU+bpOFpeHvgGOBhsjeASm+f04F5RdVgZmaby3vnbn+MATokDSJ7g7kmIm6U9BBwtaRvAfcBlxRYg5mZ1Sgs+CPiAeCd3UxfSdbeb2ZmTdCQNn4zMxs4HPxmZiXj4DczKxkHv5lZyTj4zcxKxsFvZlYyDn4zs5Jx8JuZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGSKfObu7pJuk/SQpGWSzkrTR0paIGl5+j2iqBrMzGxzRZ7xvwr8fURMAg4FzpQ0CZgFLIyIicDCNG5mZg1SWPBHxNqIuDcNPw88DIwFpgIdabEOYFpRNZiZ2eYa0sYvaTzZg9cXAaMjYm2atQ4YXWedmZI6JXV2dXU1okwzs1IoPPglDQN+CnwhIp6rnhcRAUR360XEnIhoj4j2tra2oss0MyuNQoNf0hCy0L8iIq5Pk9dLGpPmjwE2FFmDmZm9WZFX9Qi4BHg4Ir5bNWs+MD0NTwfmFVWDmZltbnCB23438DHgQUlL0rRzgNnANZJmAKuBkwuswczMahQW/BFxF6A6s6cUtV8zM+uZ79w1MysZB7+ZWckU2cZvZlaI8bNuauj+Vs0+oaH7K5rP+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrGQe/mVnJOPjNzErGwW9mVjIOfjOzknHwm5mVjIPfzKxkHPxmZiVT5DN3L5W0QdLSqmkjJS2QtDz9HlHU/s3MrHtFnvFfDhxbM20WsDAiJgIL07iZmTVQYcEfEXcCz9ZMngp0pOEOYFpR+zczs+41uo1/dESsTcPrgNH1FpQ0U1KnpM6urq7GVGdmVgJN+3I3IgKIHubPiYj2iGhva2trYGVmZlu3Rgf/ekljANLvDQ3ev5lZ6TU6+OcD09PwdGBeg/dvZlZ6RV7OeRXwG2AfSU9ImgHMBo6RtBx4Xxo3M7MGGlzUhiPio3VmTSlqn2Zm1jvfuWtmVjIOfjOzknHwm5mVjIPfzKxkCvty18xsazR+1k0N29eq2ScUsl2f8ZuZlYyD38ysZBz8ZmYl4+A3MysZB7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZWMg9/MrGQc/GZmJePgNzMrmaYEv6RjJT0qaYWkWc2owcysrBoe/JIGAd8HjgMmAR+VNKnRdZiZlVUzzvgPBlZExMqIeAW4GpjahDrMzEpJEdHYHUonAcdGxKfS+MeAQyLiszXLzQRmptF9gEcbWmjvRgFPN7uIt8D1N5frb66y1P/2iGirnThgH8QSEXOAOc2uox5JnRHR3uw6+sv1N5frb66y19+Mpp4ngd2rxndL08zMrAGaEfz3ABMlTZC0LXAqML8JdZiZlVLDm3oi4lVJnwVuBgYBl0bEskbXsQUM2GaonFx/c7n+5ip1/Q3/ctfMzJrLd+6amZWMg9/MrGQc/DlJWiXpQUlLJHWmaSMlLZC0PP0e0ew6KyRdKmmDpKVV07qtV5n/SF1oPCDpgOZV/kat3dV/nqQn07/BEknHV807O9X/qKQPNKfqN2rZXdJtkh6StEzSWWl6Sxz/HupvleO/naTfSro/1f/NNH2CpEWpzrnp4hIkDU3jK9L88QO0/sslPVZ1/Cen6X3/+4kI/+T4AVYBo2qm/SswKw3PAs5vdp1VtR0BHAAs7a1e4Hjg54CAQ4FFA7T+84Avd7PsJOB+YCgwAfgdMKiJtY8BDkjDOwH/L9XYEse/h/pb5fgLGJaGhwCL0nG9Bjg1Tb8Y+EwaPgO4OA2fCsxt8vGvV//lwEndLN/nvx+f8b81U4GONNwBTGteKW8WEXcCz9ZMrlfvVODHkbkbGC5pTEMKraNO/fVMBa6OiJcj4jFgBVnXIE0REWsj4t40/DzwMDCWFjn+PdRfz0A7/hERL6TRIekngKOB69L02uNf+Xe5DpgiSY2pdnM91F9Pn/9+HPz5BXCLpMWpOwmA0RGxNg2vA0Y3p7Tc6tU7FlhTtdwT9PwfvZk+mz7OXlrVtDZg60/NBu8kO2trueNfUz+0yPGXNEjSEmADsIDsU8jGiHg1LVJd4xv1p/l/AHZpaME1auuPiMrx/6d0/C+QNDRN6/Pxd/Dnd3hEHEDWq+iZko6onhnZZ66WuTa21epNLgL2BCYDa4F/a2o1vZA0DPgp8IWIeK56Xisc/27qb5njHxGvRcRksp4BDgb2bW5FfVNbv6T9gLPJXsdBwEjgq/3dvoM/p4h4Mv3eANxA9se0vvKRKv3e0LwKc6lXb0t0oxER69N/iNeBH7KpOWHA1S9pCFloXhER16fJLXP8u6u/lY5/RURsBG4DDiNrAqnctFpd4xv1p/k7A880ttLuVdV/bGqCi4h4GbiMt3D8Hfw5SNpR0k6VYeD9wFKyriamp8WmA/OaU2Fu9eqdD3w8XR1wKPCHqiaJAaOm3fJDZP8GkNV/aro6YwIwEfhto+urSO3DlwAPR8R3q2a1xPGvV38LHf82ScPT8PbAMWTfU9wGnJQWqz3+lX+Xk4Bb0yeypqhT/yNVJw0i+36i+vj37e+nmd9et8oPsAfZVQv3A8uAr6XpuwALgeXAL4GRza61quaryD6O/5mszW9GvXrJrgb4Plk76INA+wCt/yepvgfSH/uYquW/lup/FDiuybUfTtaM8wCwJP0c3yrHv4f6W+X4vwO4L9W5FPh6mr4H2RvSCuBaYGiavl0aX5Hm7zFA6781Hf+lwH+x6cqfPv/9uMsGM7OScVOPmVnJOPjNzErGwW9mVjIOfjOzknHwm5mVjIPftgqShks6o0H7miZp0hba1nmSvrwltmWWl4PfthbDyXpZzC3d8NKf/wPTyHqkNGtJDn7bWswG9kz9lH9b0jBJCyXdq+w5ClMh63RMWZ/xPya7EWZ3SeemaXdJuqpyBi5pT0m/SB3z/UrSvpLeBZwIfDvta89KAZJ2lrS68maS7vheI2mIpL+TdI+yPtZ/KmmH2hcg6XZJ7Wl4lKRVaXhQek33pA66Pl3sobStXcMftm5WkFnAfpF1bFXpc+VDEfGcpFHA3ZLmp2UnAtMj4m5JBwH/C9ifrPvbe4HFabk5wOkRsVzSIcCFEXF02s6NEXEdVSLiD6lHxfeSdQ/wQeDmiPizpOsj4oeptm+R3Yn8nzlf2wyy2/APSj0y/lrSLZF1gWzWZw5+21oJ+OfUi+rrZN3UVrpBXh1Zv+UA7wbmRcSfgD9J+hm80TPlu4Brtalr9ko3uD2ZC5xCFvynAhem6fulwB8ODANu7sNreT/wDkmVfmZ2JnvzcvBbvzj4bWt1GtAGHJjOuFeR9ckC8GKO9bch6799ch/3O5/sDWckcCBZ/yqQPT1pWkTcL+kTwJHdrPsqm5pft6uaLuBzEdGXNwuzutzGb1uL58keE1ixM7Ahhf5RwNvrrPdr4G+UPed0GFnzDJH1P/+YpI/AG18E719nX2+I7MlJ9wDfI2sOei3N2glYm7o7Pq1OLavI3ixgUy+SkH06+ExaF0l7p15izfrFwW9bhYh4hqzte6mkbwNXAO2SHgQ+DjxSZ717yM7SHyB7bumDZE9ggiygZ0iq9Mo6NU2/GvgHSfdVf7lbZS7wv9PvinPJnmL163q1AN8hC/j7gFFV038EPATcq+zh8z/An9btLXDvnFZ6koZFxAvpSps7gZmRnjlrtjXyWYMZzEk3ZG0HdDj0bWvnM34zs5JxG7+ZWck4+M3MSsbBb2ZWMg5+M7OScfCbmZXM/wcLRMohVH8V9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram to visualize the distribution of the \"target\" value\n",
    "plt.hist(data.frame['target'], rwidth=0.9)\n",
    "plt.title(\"Target value distribution\")\n",
    "plt.xlabel(\"target value\")\n",
    "plt.ylabel(\"#samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0964e70",
   "metadata": {},
   "source": [
    "### Prepare data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f1b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% testing\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# Remember to set random_state to control for the randomness\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5172c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature matrix\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796cd9b",
   "metadata": {},
   "source": [
    "### Fit the linear regression model on the training set and evaluate model performance on the testing set \n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca436c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression() # check the documentation to understand the default parameters\n",
    "reg.fit(X_train, y_train)\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "np.round(reg_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92373e7b",
   "metadata": {},
   "source": [
    "**Interpret model coefficients and intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f93ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  29.254, -261.706,  546.3  ,  388.398, -901.96 ,  506.763,\n",
       "        121.154,  288.035,  659.269,   41.377])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Coefficient/Weight array\n",
    "np.round(reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66d6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.008"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Intercept of the linear model\n",
    "np.round(reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a97b88",
   "metadata": {},
   "source": [
    "**Your task**: write down the linear regression model with the above coefficients and intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ee914",
   "metadata": {},
   "source": [
    "**Linear Regression Model Equation**\n",
    "\n",
    "y_hat = 151.008 + (29.254)(Age) + (-261.706)(Sex) + (546.3)(bmi) + (388.398)(bp) + (-901.96)(s1) + (506.763)(s2) + (121.154)(s3) + (288.035)(s4) + (659.269)(s5) + (41.377)(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4c48",
   "metadata": {},
   "source": [
    "**Your task**: explore other parameters/attributes/methods\n",
    "- fit_intercept\n",
    "- feature_names_in_, n_features_in_\n",
    "Write your exploration code and results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13242258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check whether the intercept is set to 0 or determined by the linear regression model. If False, the intercept = 0.\n",
    "reg.fit_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0c92ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Names of features from the training data\n",
    "reg.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc280db1",
   "metadata": {},
   "source": [
    "### Fit and evaluate a Ridge regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71a8d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.423"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With L2 penalty\n",
    "rg_reg = Ridge()\n",
    "rg_reg.fit(X_train, y_train)\n",
    "rg_reg_score = rg_reg.score(X_test, y_test)\n",
    "np.round(rg_reg_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c783ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45.054,  -71.947,  280.716,  195.213,   -2.229,  -17.541,\n",
       "       -148.689,  120.467,  198.614,  106.935])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4deaa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.867"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58d2f",
   "metadata": {},
   "source": [
    "### Your task: fit and evaluate a Lasso regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c416398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "#With L1 penalty\n",
    "Lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71c90cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "Lasso.fit(X_train, y_train)\n",
    "np.round(Lasso.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c5dea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,  -0.   , 443.703,  51.601,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   , 201.966,   0.   ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpret model coefficients and intercept\n",
    "np.round(Lasso.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "903b41ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.166"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Lasso.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950962e",
   "metadata": {},
   "source": [
    "### Your task: compare the linear/ridge/lasso regression models\n",
    "- write down your code to create and display the given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92e90c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "      <td>45.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "      <td>-71.947</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "      <td>280.716</td>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "      <td>195.213</td>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "      <td>-17.541</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "      <td>-148.689</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "      <td>120.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "      <td>198.614</td>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "      <td>106.935</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.867</td>\n",
       "      <td>152.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear    ridge    lasso\n",
       "age         29.254   45.054    0.000\n",
       "sex       -261.706  -71.947   -0.000\n",
       "bmi        546.300  280.716  443.703\n",
       "bp         388.398  195.213   51.601\n",
       "s1        -901.960   -2.229    0.000\n",
       "s2         506.763  -17.541    0.000\n",
       "s3         121.154 -148.689   -0.000\n",
       "s4         288.035  120.467    0.000\n",
       "s5         659.269  198.614  201.966\n",
       "s6          41.377  106.935    0.000\n",
       "intercept  151.008  151.867  152.166\n",
       "score        0.477    0.423    0.362"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: the following dataframe shows the expected way to organize and display the information\n",
    "# make sure to: \n",
    "# - round to 3 digits after the decimal point\n",
    "# - rename the column names \n",
    "# - include intercept and score in the last two rows\n",
    "\n",
    "row_names = dict([item for item in zip(range(12), list(reg.feature_names_in_) + ['intercept', 'score'])])\n",
    "\n",
    "np.round(pd.DataFrame({'linear':list(reg.coef_) + [reg.intercept_, reg.score(X_test, y_test)],\n",
    "             'ridge': list(rg_reg.coef_) + [rg_reg.intercept_, rg_reg.score(X_test, y_test)],\n",
    "             'lasso': list(Lasso.coef_) + [Lasso.intercept_, Lasso.score(X_test, y_test)]}).rename(index=row_names), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7e638",
   "metadata": {},
   "source": [
    "**Your observations and thoughts of comparing the three models**\n",
    "- hint: connect this with what we discussed in the lectures, e.g.\n",
    "    - how does regularization affect coefficients and model performance \n",
    "    - what is the difference between ridge (L2 penalty) and Lasso (L1 penalty) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7edab5a",
   "metadata": {},
   "source": [
    "* The Lasso regression model has more features with coefficients equal to 0, which yields sparsity within the model.\n",
    "* Only 'bmi', 'bp', 's5' are considered in the Lasso model with non-zero coefficients\n",
    "* In Lasso regression model, the absolute sum of the weights (L1 panelty) is added to the loss function, which shrink some of the coefficients toward 0. \n",
    "* All coefficients in the Ridge model are non-zero values due to the squared regularization term. \n",
    "* The linear regression model without regularization has the largest coefficients compared to regularized models.\n",
    "* The intercepts of three regression models are similar. Regularization only affects the coefficients.\n",
    "* The linear model have the large coefficients compared to Ridge and Lasso model, which may cause overfitting of the training data.\n",
    "* Use the results from Lasso model for feature selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca80a6",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "- Use the diabetes data with the same train and test set to fit several **Polynomial regression** models \n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaa8fc",
   "metadata": {},
   "source": [
    "### Fit a polynomail regression model with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c660e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 66)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the training data \n",
    "# \"fit_transform\" on the original training data\n",
    "\n",
    "poly2 = PolynomialFeatures(2)\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "X_train_poly2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da88debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 66)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the testing data \n",
    "# only do \"transform\" on the original testing feature matrix\n",
    "# why do we do \"fit_transform\" on training data but only do \"transform\" on testing data?\n",
    "\n",
    "X_test_poly2 = poly2.transform(X_test)\n",
    "X_test_poly2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e5978",
   "metadata": {},
   "source": [
    "**why do we do \"fit_transform\" on training data but only do \"transform\" on testing data?**\n",
    "* The purpose of doing \"fit_transform\" on training data is to obtain the scaling parameters (mean and standard deviation).\n",
    "* The purpose of doing “transfom\" on testing data is to apply the scaling to the testing data.\n",
    "* We don't use \"fit_transform\" on testing data because we don't need to learn from the pattern of testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de488def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.413"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression model with the newly generated polynomial feature matrix \n",
    "# evaluate model performance \n",
    "\n",
    "poly2_reg = LinearRegression()\n",
    "poly2_reg.fit(X_train_poly2, y_train)\n",
    "poly2_score = poly2_reg.score(X_test_poly2, y_test)\n",
    "np.round(poly2_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72079596",
   "metadata": {},
   "source": [
    "### Your task: fit a polynomail regression model with degree=1\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=1** (name it as $poly1\\_reg$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e53f151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the training data\n",
    "poly1 = PolynomialFeatures(1)\n",
    "X_train_poly1 = poly1.fit_transform(X_train)\n",
    "X_train_poly1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "794b0562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 11)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the testing data \n",
    "X_test_poly1 = poly1.transform(X_test)\n",
    "X_test_poly1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f9e86ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression model with the newly generated polynomial feature matrix \n",
    "# evaluate model performance \n",
    "poly1_reg = LinearRegression()\n",
    "poly1_reg.fit(X_train_poly1, y_train)\n",
    "poly1_score = poly1_reg.score(X_test_poly1, y_test)\n",
    "np.round(poly1_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b9642",
   "metadata": {},
   "source": [
    "### Your task: fit a polynomail regression model with degree=3\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=3** (name it as $poly3\\_reg$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8760be74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 286)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the training data\n",
    "poly3 = PolynomialFeatures(3)\n",
    "X_train_poly3 = poly3.fit_transform(X_train)\n",
    "X_train_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c0b9490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 286)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the testing data \n",
    "X_test_poly3 = poly3.transform(X_test)\n",
    "X_test_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d29a3915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-91.718"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression model with the newly generated polynomial feature matrix \n",
    "# evaluate model performance \n",
    "poly3_reg = LinearRegression()\n",
    "poly3_reg.fit(X_train_poly3, y_train)\n",
    "poly3_score = poly3_reg.score(X_test_poly3, y_test)\n",
    "np.round(poly3_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc159ab",
   "metadata": {},
   "source": [
    "### Your task: compare the polynomial regression models with degree=1/2/3 and the original linear regression model\n",
    "- please write code to create and display the given data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44f9e382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>poly_d1</th>\n",
       "      <th>poly_d2</th>\n",
       "      <th>poly_d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.008</td>\n",
       "      <td>-360.919</td>\n",
       "      <td>-2.371637e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-9.171800e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear  poly_d1  poly_d2       poly_d3\n",
       "intercept  151.008  151.008 -360.919 -2.371637e+16\n",
       "score        0.477    0.477    0.413 -9.171800e+01"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_names = dict([item for item in zip(range(2), ['intercept', 'score'])])\n",
    "\n",
    "np.round(pd.DataFrame({'linear': [reg.intercept_, reg.score(X_test, y_test)],\n",
    "             'poly_d1': [poly1_reg.intercept_, poly1_reg.score(X_test_poly1, y_test)],\n",
    "             'poly_d2': [poly2_reg.intercept_, poly2_reg.score(X_test_poly2, y_test)],\n",
    "             'poly_d3': [poly3_reg.intercept_, poly3_reg.score(X_test_poly3, y_test)]}).rename(index=row_names), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b17b2",
   "metadata": {},
   "source": [
    "### Your task: observations and thoughts of comparing the above four models\n",
    "- hint: connect this with overfitting/underfitting we discussed in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f34a6",
   "metadata": {},
   "source": [
    "* Linear and poly_d1 models have identical intercepts and scores. Polynomial model with degree = 1 is simply a linear model\n",
    "* poly_d2 model has a lower score and a large negative value. Adding one degree to the model does not help in improving model's performance because the data probably does not have a quadratic relationship.\n",
    "* poly_d3 model has a extremely large intercept and low negative score. Polynomial with degree of 3 is too complex to fit the data.\n",
    "* poly_d2 and poly_d3 models are more prone to overfitting because higher-order polynomial models tend to capture the noise and random variations in the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e005bd8",
   "metadata": {},
   "source": [
    "### Your task: interpret the model performance wrt the task itself\n",
    "- how does each feature relate with diabetes\n",
    "- which factors contribute positively/negatively/most/least to diabetes\n",
    "- does these statistical correlations make sense from biological perspective? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4716fd",
   "metadata": {},
   "source": [
    "* Age, bmi, bp, s2 (low-density lipoproteins), s3 (high-density lipoproteins), s5 (possibly log of serum triglycerides level), and s6 (blood sugar level) contributed positively to diabetes.\n",
    "* Sex and s1 (total serum cholesterol) contributed negatively to diabetes. \n",
    "* Lasso model can be used for feature selections. The most significant factors identified with L1 penalty were bmi, bp, and s5. \n",
    "* The factors that contributed the least to diabetes were age, sex, s1, s2, s3, s4, and s6, as their coefficients were shrunk to smller numbers and even zero after introducing the L1 and L2 regularization terms.\n",
    "* These statistical correlations make sense from biological perspective. High BMI and Higher blood pressure are the well-known risk indicators of diabates. Also, elevated triglycerides level are common in diabetes patients since the insulin resistance (where the body is unable to take up glucose for energy) causes patients to break downn fats for the use of energy. Therefore, the level of fat (triglycerides) is higher for diabetes patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82f53",
   "metadata": {},
   "source": [
    "## Linear models for classification: LogisticRegression \n",
    "In this section, we will work on a banknote authentication dataset:\n",
    "- Original data source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication <br>\n",
    "\n",
    "This dataset contains n = 1372 images of genuine and forged banknote-like specimens. Each image is represented by four features extracted from Wavelet Transform tool: \n",
    "    1. variance (continuous) \n",
    "    2. skewness (continuous)\n",
    "    3. curtosis (continuous)\n",
    "    4. entropy of image (continuous)\n",
    "\n",
    "And each image has a binary label of 0/1 indicating whether the banknote is forged or genuine.\n",
    "\n",
    "We will fit several logistic regression models with different parameter settings to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target values <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different logistic regression models (vary by parameter settings) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "574468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf817f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change to your file path\n",
    "df_data = pickle.load(open('./banknote_authentication_dataframe.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a442ec9",
   "metadata": {},
   "source": [
    "### Basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a876742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699    0.0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210    0.0\n",
       "2      3.86600  -2.63830    1.9242  0.10645    0.0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440    0.0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880    0.0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949    1.0\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179    1.0\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710    1.0\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230    1.0\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520    1.0\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataset\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "222a148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data \n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbafff",
   "metadata": {},
   "source": [
    "### Prepara data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1fbc714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1372, 4), (1372,), Counter({0.0: 762, 1.0: 610}))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['variance','skewness','curtosis','entropy']\n",
    "\n",
    "# Construct feature matrix from the data frame\n",
    "X_data = df_data[feature_names]\n",
    "y_data = df_data['class']\n",
    "X_data.shape, y_data.shape, Counter(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "98dc3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 70% training and 30% testing using train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bb9b2",
   "metadata": {},
   "source": [
    "### Fit LogisticRegression models with different parameter settings\n",
    "- L1 VS L2 penalty\n",
    "- C values (inverse of regularization strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e206acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb8b57ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0baa21e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2525662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.982, 0.018],\n",
       "       [0.996, 0.004]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ff19c",
   "metadata": {},
   "source": [
    "**Your task**: explore at least one different set of parameters to re-fit the model: solver, penalty, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "598e50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver = ‘saga', penalty = 'elasticnet', C=2.0\n",
    "clf1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=2.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2aef2be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b3b5be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f16777e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.978, 0.022],\n",
       "       [0.994, 0.006]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf1.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5d0d1",
   "metadata": {},
   "source": [
    "### Compare model performance with different c values and different penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9160ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_c(X_train, y_train, X_test, y_test, p):\n",
    "    \"\"\"\n",
    "    X_train/test: 2D feature matrix of training/testing data\n",
    "    y_train/test: 1D array of training/testing labels\n",
    "    p: the penalty parameter setting in LogisticRegression\n",
    "    \n",
    "    return: \n",
    "        a list of classifiers fitted with different c values\n",
    "        a dataframe that is shown in the running example below\n",
    "    \"\"\"\n",
    "     \n",
    "    # set the model parameter c to different values and train the model \n",
    "    # for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    #    fit a LogisticRegression model with: the current c value, the given penalty p, set random_state=42, max_iter=1000, solver='liblinear', and use default setting for other parameters\n",
    "    #    test and record the model performance \n",
    "    #    get the statistical information about the model coefficients: \n",
    "    #        min: minimum coefficient\n",
    "    #        max: minimum coefficient\n",
    "    #        mean(abs(coef)): average over the absolute coefficient values\n",
    "    #        n_zero: number of coefficients equal to zero \n",
    "    \n",
    "    ### Your code starts from here \n",
    "    \n",
    "    classifier = []\n",
    "    df = []\n",
    "    \n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        comp = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', C=c, penalty=p)\n",
    "        comp.fit(X_train, y_train)\n",
    "        \n",
    "        coef = comp.coef_\n",
    "        \n",
    "        score = comp.score(X_test, y_test)\n",
    "        min_coef = np.min(coef)\n",
    "        max_coef = np.max(coef)\n",
    "        average_coef = np.mean(np.abs(coef))\n",
    "        zero_coef = np.sum(coef == 0)\n",
    "        \n",
    "        df.append({\"c\":c, \"min\" : min_coef, \"max\" : max_coef, \n",
    "                        \"mean_abs\": average_coef, \"n_zero\": zero_coef, \n",
    "                        \"test_score\": score})\n",
    "        \n",
    "        classifier.append(comp)\n",
    "        \n",
    "    df = np.round(pd.DataFrame(df), 3)\n",
    "          \n",
    "    return classifier, df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d7fb1b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.581</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.835</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-5.171</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>2.937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-7.648</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>4.297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c    min    max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.357 -0.074     0.190       0       0.922\n",
       "1    0.010 -0.861 -0.173     0.485       0       0.973\n",
       "2    0.100 -1.581 -0.163     0.915       0       0.988\n",
       "3    1.000 -2.835 -0.166     1.645       0       0.988\n",
       "4   10.000 -5.171 -0.290     2.937       0       0.988\n",
       "5  100.000 -7.648 -0.438     4.297       0       0.990"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l2_clfs, c_effect_l2 = compare_c(X_train, y_train, X_test, y_test, p='l2')\n",
    "c_effect_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "65387db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.001, max_iter=1000, random_state=42, solver='liblinear'),\n",
       " LogisticRegression(C=0.01, max_iter=1000, random_state=42, solver='liblinear'),\n",
       " LogisticRegression(C=0.1, max_iter=1000, random_state=42, solver='liblinear'),\n",
       " LogisticRegression(C=1, max_iter=1000, random_state=42, solver='liblinear'),\n",
       " LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear'),\n",
       " LogisticRegression(C=100, max_iter=1000, random_state=42, solver='liblinear')]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7bd278a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.838</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>2.164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-7.110</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>3.993</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-8.196</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>4.596</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c    min    max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.042  0.000     0.010       3       0.624\n",
       "1    0.010 -0.807  0.000     0.328       1       0.917\n",
       "2    0.100 -1.750  0.000     0.936       1       0.988\n",
       "3    1.000 -3.838 -0.132     2.164       0       0.988\n",
       "4   10.000 -7.110 -0.389     3.993       0       0.990\n",
       "5  100.000 -8.196 -0.464     4.596       0       0.990"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l1_clfs, c_effect_l1, coef = compare_c(X_train, y_train, X_test, y_test, p='l1')\n",
    "c_effect_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8b2b9cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.001, max_iter=1000, penalty='l1', random_state=42,\n",
       "                    solver='liblinear'),\n",
       " LogisticRegression(C=0.01, max_iter=1000, penalty='l1', random_state=42,\n",
       "                    solver='liblinear'),\n",
       " LogisticRegression(C=0.1, max_iter=1000, penalty='l1', random_state=42,\n",
       "                    solver='liblinear'),\n",
       " LogisticRegression(C=1, max_iter=1000, penalty='l1', random_state=42,\n",
       "                    solver='liblinear'),\n",
       " LogisticRegression(C=10, max_iter=1000, penalty='l1', random_state=42,\n",
       "                    solver='liblinear'),\n",
       " LogisticRegression(C=100, max_iter=1000, penalty='l1', random_state=42,\n",
       "                    solver='liblinear')]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5b421850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.75023572, -0.90859922, -1.08460709,  0.        ]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', C=0.1, penalty = 'l1')\n",
    "comp.fit(X_train, y_train)       \n",
    "coef = comp.coef_\n",
    "coef\n",
    "#See which features are significant using model with score = 0.988 (c=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a8855",
   "metadata": {},
   "source": [
    "**Your thoughts and observations:** \n",
    "  - explain model performance from the perspective of under-fitting VS over-fitting\n",
    "  - compare the two tables and indicate the difference between L1 and L2 penalty\n",
    "  - how does c affect coefficients and model performance in each table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f817a67",
   "metadata": {},
   "source": [
    "* C = Inverse of regularization strength. Smaller values specify stronger regularization\n",
    "\n",
    "* Model with L1 penalty performed poorly when using c=0.001, and model with L2 penalty at c=0.001 also had the lowest test score.\n",
    "* Strong regularzation (smaller c value) leads to lower model's performance and may lead to underfitting.\n",
    "* The weaker the regularization, the higher the scores are. Typically, we would expect a lesser degree of regularization to lead to overfitting of the training data. However, overfitting is not occuring in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ec92a",
   "metadata": {},
   "source": [
    "* L1 penalty moved some coefficients to zero.\n",
    "* With L1 penalty, as c value increased, the test score increased (Large difference between c = 0.001 and c = 0.010) and the numbers of zero coefficients decreased. \n",
    "* L2 penalty did not push any coefficients to zero.\n",
    "* With L2 penalty, as c value increased, the test score gradually increased, which indicated model with L2 penalty would have a stable performance.\n",
    "* As c value reached to 0.100, the scores of both L1 and L2 almost became the same. (0.988 ~ 0.990)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39d68",
   "metadata": {},
   "source": [
    "### Interpret the model performance wrt the banknote authentication task\n",
    "- how does each feature relate with the identification of genuine and forged banknote\n",
    "- does these statistical correlations make sense from the perspective of image recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172224e7",
   "metadata": {},
   "source": [
    "* The models' performance show high accruacy with moderate level of regularization. \n",
    "* Utilizing L1 regularization for feature selections, variance, skewness, and curtosis are significant features in identifying genuine and forges banknote.\n",
    "* Entropy may not be significant becasuse both genuine and forged banknote are showing a similar amount of information, which makes entropy not as helpful as the other features in distinguishing real or fake banknote. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bcb91b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Congratulations for completing this exercise! In this notebook, with hands-on practice of linear models for regression and classification tasks, we gain deep understanding of:\n",
    "- overfitting VS underfitting\n",
    "- difference between l1 and l2 regularizations\n",
    "- the effect of regularization strength on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df471",
   "metadata": {},
   "source": [
    "## Which part(s) you find most interesting/chanlleging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21d3a6",
   "metadata": {},
   "source": [
    "* I found that the application and impact of L1 and L2 regularizations interesting, especially how they influenced feature selection and model complexity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
